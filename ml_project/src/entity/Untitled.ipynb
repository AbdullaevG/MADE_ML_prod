{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7b3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import click\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa1637",
   "metadata": {},
   "source": [
    "#### 1. Download parameters for pipeline from configs_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b150c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from marshmallow_dataclass import class_schema\n",
    "import yaml\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.3\n",
    "N_ESTIMATORS = 100\n",
    "\n",
    "\n",
    "@dataclass()\n",
    "class DownloadingParams:\n",
    "    \"\"\" Structure for train model parameters \"\"\"\n",
    "    file_link: str = field()\n",
    "    output_folder: str = field(default=\"data/raw/\")\n",
    "    name: str = field(default=\"data.zip\")\n",
    "        \n",
    "@dataclass\n",
    "class SplittingParams:\n",
    "    \"\"\" Structure contain parameters for splitting data \"\"\"\n",
    "    test_size: float = field(default=TEST_SIZE)\n",
    "    random_state: int = field(default=RANDOM_STATE)\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class FeatureParams:\n",
    "    \"\"\" Structure contain categorical and numerical params in dataset\"\"\"\n",
    "    cat_features: List[str]\n",
    "    num_features: List[str]\n",
    "    target: Optional[str]\n",
    "\n",
    "@dataclass\n",
    "class OutliersNulls:\n",
    "    \"\"\" Structure contain parameters for preparing data \"\"\"\n",
    "    outliers: str = field(default= 'RestingBP')\n",
    "    nulls: str = field(default= 'Cholesterol')\n",
    "    target: str = field(default='HeartDisease')\n",
    "        \n",
    "MEAN_SAMPLES_LEAF = 5\n",
    "CRITERION = \"gini\"\n",
    "\n",
    "@dataclass()\n",
    "class ModelType:\n",
    "    \"\"\" Structure for train model parameters \"\"\"\n",
    "    model_type: str = field(default='RandomForestClassifier')\n",
    "    n_estimators: int = field(default=N_ESTIMATORS)\n",
    "    min_samples_leaf: int = field(default=MEAN_SAMPLES_LEAF)\n",
    "    criterion: str = field(default=CRITERION)\n",
    "    random_state: int = field(default=RANDOM_STATE)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CustomTransformer:\n",
    "    \"\"\" Structure contain switch for custom transformer \"\"\"\n",
    "    use_custom_transformer: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb8afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingPipelineParams:\n",
    "    \"\"\"Structure for pipeline parameters\"\"\"\n",
    "    input_data_path: str\n",
    "    metric_path: str\n",
    "    save_model_path: str\n",
    "    save_transformer_path: str\n",
    "    downloading_params: DownloadingParams\n",
    "    model_type: ModelType\n",
    "    clean_features: OutliersNulls\n",
    "    custom_transformer: CustomTransformer\n",
    "    feature_params: FeatureParams\n",
    "    splitting_params: SplittingParams\n",
    "\n",
    "\n",
    "TrainingPipelineParamsSchema = class_schema(TrainingPipelineParams)\n",
    "\n",
    "\n",
    "def read_training_pipeline_params(path: str) -> TrainingPipelineParams:\n",
    "    with open(path, \"r\") as input_stream:\n",
    "        schema = TrainingPipelineParamsSchema()\n",
    "        return schema.load(yaml.safe_load(input_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a548de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingPipelineParams(input_data_path='data/raw/heart.csv', metric_path='models/metrics_train_random_forest.json', save_model_path='models/random_forest.pkl', save_transformer_path='models/transformer_random_forest.pkl', downloading_params=DownloadingParams(file_link='https://drive.google.com/file/d/1FU8p1PG7O_nGKvpjFXuXfoWDPCBvm8xS/view?usp=sharing', output_folder='data/raw/', name='data.zip'), model_type=ModelType(model_type='RandomForestClassifier', n_estimators=200, min_samples_leaf=5, criterion='gini', random_state=42), clean_features=OutliersNulls(outliers='RestingBP', nulls='Cholesterol', target='HeartDisease'), custom_transformer=CustomTransformer(use_custom_transformer=False), feature_params=FeatureParams(cat_features=['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], num_features=['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak'], target='HeartDisease'), splitting_params=SplittingParams(test_size=0.3, random_state=0))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"../../configs/train_config_random_forest.yaml\"\n",
    "training_pipeline_params: TrainingPipelineParams = read_training_pipeline_params(config_path)\n",
    "\n",
    "training_pipeline_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba71ed39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DownloadingParams(file_link='https://drive.google.com/file/d/1FU8p1PG7O_nGKvpjFXuXfoWDPCBvm8xS/view?usp=sharing', output_folder='data/raw/', name='data.zip')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.downloading_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ce18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae36934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset... \n",
      "Dataset was downloaded\n"
     ]
    }
   ],
   "source": [
    "def download_data(url: str, output_file_path: str):\n",
    "    logger.info(\"Loading dataset... \")\n",
    "    try:\n",
    "        gdown.download(url=url, output=output_file_path, fuzzy=True, quiet=True)\n",
    "        logger.info(\"Dataset was downloaded\")\n",
    "    except ConnectionError:\n",
    "        logger.info(\"ConnectionError: you should have link to the internet!\")\n",
    "\n",
    "url = training_pipeline_params.downloading_params.file_link\n",
    "output = \"../../\" + training_pipeline_params.downloading_params.output_folder + training_pipeline_params.downloading_params.name\n",
    "download_data(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5e504aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/raw/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.downloading_params.output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09694468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def unzip_downloaded_data(path_to_zip_file: str):\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path_to_zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6c724dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ../../data/raw/heart.csv...\n",
      "Loading from ../../data/raw/heart.csv finished\n",
      "Data shape (918, 12)\n"
     ]
    }
   ],
   "source": [
    "def read_raw_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read data from csv file\"\"\"\n",
    "    logger.info('Loading dataset from %s...', path)\n",
    "    df = pd.read_csv(path)\n",
    "    logger.info('Loading from %s finished', path)\n",
    "    logger.info('Data shape %s', df.shape)\n",
    "    return df\n",
    "#                                 training_pipeline_params.input_data_path\n",
    "df: pd.DataFrame = read_raw_data('../../' + training_pipeline_params.input_data_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a87122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional\n",
    "def prepare_data(df: pd.DataFrame, params) -> Tuple[pd.DataFrame, Optional[pd.Series]]:\n",
    "    \"\"\"Prepare data\"\"\"\n",
    "    logger.info('Preparing dataset...')\n",
    "    logger.info('Outliers handling...')\n",
    "    outliers_field = params.outliers\n",
    "    row = df[df[outliers_field] == 0].index\n",
    "    df = df.drop(df.index[row])\n",
    "\n",
    "    logger.info('Nulls handling...')\n",
    "    nulls_field = params.nulls\n",
    "    median_values = df[nulls_field].median()\n",
    "    row = df[df[nulls_field] == 0].index\n",
    "    df.loc[row, nulls_field] = median_values\n",
    "\n",
    "    target_name = params.target\n",
    "    if target_name in df.columns:\n",
    "        logger.info('Extract and drop target feature...')\n",
    "        target = df[target_name]\n",
    "        df = df.drop([target_name], axis=1)\n",
    "        return df, target\n",
    "    else:\n",
    "        return df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca1f2f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutliersNulls(outliers='RestingBP', nulls='Cholesterol', target='HeartDisease')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.clean_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01245280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Outliers handling...\n",
      "Nulls handling...\n",
      "Extract and drop target feature...\n"
     ]
    }
   ],
   "source": [
    "df, target = prepare_data(df, training_pipeline_params.clean_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac6a289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplittingParams(test_size=0.3, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.splitting_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d9e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(df: pd.DataFrame,\n",
    "               target: pd.Series,\n",
    "               params) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"Split data to train and test\"\"\"\n",
    "    logger.info('Splitting data into train and test...')\n",
    "    (X_train, X_test, y_train, y_test) = train_test_split(df,\n",
    "                                                          target,\n",
    "                                                          test_size=params.test_size,\n",
    "                                                          random_state=params.random_state,\n",
    "                                                          stratify=target)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "352aff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and test...\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, train_target, test_target = split_data(df, target,\n",
    "                                                          training_pipeline_params.splitting_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10ce993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureParams(cat_features=['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], num_features=['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak'], target='HeartDisease')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.feature_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7a8edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def build_feature_transformer(params):\n",
    "    num_transformer = Pipeline(steps=[('min_max', MinMaxScaler())])\n",
    "    cat_transformer = Pipeline(steps=[('one_hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numerical', num_transformer, params.num_features),\n",
    "            ('categorical', cat_transformer, params.cat_features)])\n",
    "\n",
    "    preprocessing = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "    return preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "976ae20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transformer(transformer: ColumnTransformer, df_train: pd.DataFrame):\n",
    "    \"\"\"Fitting transformer with train data\"\"\"\n",
    "    transformer.fit(df_train)\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c29f8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(transformer: ColumnTransformer, df: pd.DataFrame):\n",
    "    \"\"\" Get transformed data \"\"\"\n",
    "    return transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5cd3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = build_feature_transformer(training_pipeline_params.feature_params)\n",
    "transformer = fit_transformer(transformer, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c477e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = get_features(transformer, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58acf505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureParams(cat_features=['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], num_features=['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak'], target='HeartDisease')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.feature_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffd92b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from typing import Union\n",
    "SklearnClassificationModel = Union[RandomForestClassifier, GradientBoostingClassifier]\n",
    "\n",
    "def train_model(df: pd.DataFrame, target: pd.Series, train_params) -> SklearnClassificationModel:\n",
    "    \"\"\"Get trained model\"\"\"\n",
    "    logger.info('Start loading %s model...', train_params.model_type)\n",
    "\n",
    "    if train_params.model_type == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier()\n",
    "    \n",
    "    elif train_params.model_type == 'GradientBoostingClassifier':\n",
    "        model = GradientBoostingClassifier()\n",
    "    \n",
    "    else:\n",
    "        logger.exception('Model is incorrect')\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    logger.info('Finished loading model')\n",
    "    logger.info('Start model fitting...')\n",
    "    model.fit(df, target)\n",
    "    logger.info('Finished model fitting')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8760538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelType(model_type='RandomForestClassifier', n_estimators=200, min_samples_leaf=5, criterion='gini', random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0074f91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c946dbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading RandomForestClassifier model...\n",
      "Finished loading model\n",
      "Start model fitting...\n",
      "Finished model fitting\n"
     ]
    }
   ],
   "source": [
    "model = train_model(train_features, train_target, training_pipeline_params.model_type )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a632d9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/metrics_train_random_forest.json'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.metric_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d496670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=200, min_samples_leaf=5, min_samples_split=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f875d4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(min_samples_leaf=5, min_samples_split=10,\n",
       "                           n_estimators=200)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3eca718d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GradientBoostingClassifier'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gbc).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "feebf10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/random_forest.pkl'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_params.save_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed287cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
